{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader, TensorDataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test=np.load('X_test.npy')\n",
    "y_test=np.load('y_test.npy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "HybridCNNTransformer(\n",
      "  (cnn_unit): CNNLayer(\n",
      "    (units): Sequential(\n",
      "      (0): CNNUnit(\n",
      "        (conv): Conv2d(22, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "        (bn): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu): ReLU(inplace=True)\n",
      "      )\n",
      "      (1): CNNUnit(\n",
      "        (conv): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "        (bn): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu): ReLU(inplace=True)\n",
      "      )\n",
      "      (2): CNNUnit(\n",
      "        (conv): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "        (bn): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu): ReLU(inplace=True)\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (cnn1): CNNLayer(\n",
      "    (units): Sequential(\n",
      "      (0): CNNUnit(\n",
      "        (conv): Conv2d(16, 24, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
      "        (bn): BatchNorm2d(24, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu): ReLU(inplace=True)\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (transformer1): TransformerBlock(\n",
      "    (transformer): TransformerEncoderLayer(\n",
      "      (self_attn): MultiheadAttention(\n",
      "        (out_proj): NonDynamicallyQuantizableLinear(in_features=24, out_features=24, bias=True)\n",
      "      )\n",
      "      (linear1): Linear(in_features=24, out_features=2048, bias=True)\n",
      "      (dropout): Dropout(p=0.1, inplace=False)\n",
      "      (linear2): Linear(in_features=2048, out_features=24, bias=True)\n",
      "      (norm1): LayerNorm((24,), eps=1e-05, elementwise_affine=True)\n",
      "      (norm2): LayerNorm((24,), eps=1e-05, elementwise_affine=True)\n",
      "      (dropout1): Dropout(p=0.1, inplace=False)\n",
      "      (dropout2): Dropout(p=0.1, inplace=False)\n",
      "    )\n",
      "  )\n",
      "  (cnn2): CNNLayer(\n",
      "    (units): Sequential(\n",
      "      (0): CNNUnit(\n",
      "        (conv): Conv2d(24, 32, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
      "        (bn): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu): ReLU(inplace=True)\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (transformer2): TransformerBlock(\n",
      "    (transformer): TransformerEncoderLayer(\n",
      "      (self_attn): MultiheadAttention(\n",
      "        (out_proj): NonDynamicallyQuantizableLinear(in_features=32, out_features=32, bias=True)\n",
      "      )\n",
      "      (linear1): Linear(in_features=32, out_features=2048, bias=True)\n",
      "      (dropout): Dropout(p=0.1, inplace=False)\n",
      "      (linear2): Linear(in_features=2048, out_features=32, bias=True)\n",
      "      (norm1): LayerNorm((32,), eps=1e-05, elementwise_affine=True)\n",
      "      (norm2): LayerNorm((32,), eps=1e-05, elementwise_affine=True)\n",
      "      (dropout1): Dropout(p=0.1, inplace=False)\n",
      "      (dropout2): Dropout(p=0.1, inplace=False)\n",
      "    )\n",
      "  )\n",
      "  (avg_pool): AdaptiveAvgPool2d(output_size=(1, 1))\n",
      "  (fc1): Linear(in_features=32, out_features=512, bias=True)\n",
      "  (fc2): Linear(in_features=512, out_features=2, bias=True)\n",
      "  (dropout): Dropout(p=0.5, inplace=False)\n",
      "  (flatten): Flatten(start_dim=1, end_dim=-1)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "channels=22\n",
    "class CNNUnit(nn.Module):\n",
    "    def __init__(self, in_channels, out_channels, stride=1):\n",
    "        super(CNNUnit, self).__init__()\n",
    "        self.conv = nn.Conv2d(in_channels, out_channels, kernel_size=3, stride=stride, padding=1)\n",
    "        self.bn = nn.BatchNorm2d(out_channels)\n",
    "        self.relu = nn.ReLU(inplace=True)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.conv(x)\n",
    "        x = self.bn(x)\n",
    "        x = self.relu(x)\n",
    "        return x\n",
    "\n",
    "class CNNLayer(nn.Module):\n",
    "    def __init__(self, in_channels, out_channels, num_units, stride=1):\n",
    "        super(CNNLayer, self).__init__()\n",
    "        units = []\n",
    "        for _ in range(num_units):\n",
    "            units.append(CNNUnit(in_channels, out_channels, stride))\n",
    "            in_channels = out_channels  # 更新输入通道数\n",
    "        self.units = nn.Sequential(*units)\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.units(x)\n",
    "\n",
    "class TransformerBlock(nn.Module):\n",
    "    def __init__(self, feature_size, num_heads, dropout_rate):\n",
    "        super(TransformerBlock, self).__init__()\n",
    "        self.transformer = nn.TransformerEncoderLayer(\n",
    "            d_model=feature_size,\n",
    "            nhead=num_heads,\n",
    "            dropout=dropout_rate\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.transformer(x)\n",
    "\n",
    "class HybridCNNTransformer(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(HybridCNNTransformer, self).__init__()\n",
    "        # CNN Unit (assuming input channels is 1 for STFT)\n",
    "        self.cnn_unit = CNNLayer(in_channels=channels, out_channels=16, num_units=3)\n",
    "        \n",
    "        # CNN and Transformer layers\n",
    "        self.cnn1 = CNNLayer(in_channels=16, out_channels=24, num_units=1, stride=2)\n",
    "        self.transformer1 = TransformerBlock(feature_size=24, num_heads=8, dropout_rate=0.1)\n",
    "        \n",
    "        self.cnn2 = CNNLayer(in_channels=24, out_channels=32, num_units=1, stride=2)\n",
    "        self.transformer2 = TransformerBlock(feature_size=32, num_heads=8, dropout_rate=0.1)\n",
    "        \n",
    "        # Pooling layer\n",
    "        self.avg_pool = nn.AdaptiveAvgPool2d((1, 1))\n",
    "        \n",
    "        # Fully connected layers\n",
    "        self.fc1 = nn.Linear(32, 512)\n",
    "        self.fc2 = nn.Linear(512, 2)\n",
    "        self.dropout = nn.Dropout(0.5)\n",
    "        self.flatten = nn.Flatten()\n",
    "\n",
    "    def forward(self, x):\n",
    "        # Initial CNN processing\n",
    "        x = self.cnn_unit(x)\n",
    "        \n",
    "        # First CNN and Transformer stage\n",
    "        x = self.cnn1(x)\n",
    "        x = x.flatten(2)  # Flatten the CNN features for the transformer\n",
    "        x = x.permute(2, 0, 1)  # Reshape for transformer (Seq, Batch, Feature)\n",
    "        x = self.transformer1(x)\n",
    "        x = x.permute(1, 2, 0).unsqueeze(-1)  # Reshape back (Batch, Feature, Seq, 1)\n",
    "        \n",
    "        # Second CNN and Transformer stage\n",
    "        x = self.cnn2(x)\n",
    "        x = x.flatten(2)  # Flatten the CNN features for the transformer\n",
    "        x = x.permute(2, 0, 1)  # Reshape for transformer\n",
    "        x = self.transformer2(x)\n",
    "        x = x.permute(1, 2, 0).unsqueeze(-1)  # Reshape back\n",
    "        \n",
    "        # Pooling and fully connected layers\n",
    "        x = self.avg_pool(x)\n",
    "        x = self.flatten(x)\n",
    "        x = self.fc1(x)\n",
    "        x = self.dropout(x)\n",
    "        x = self.fc2(x)\n",
    "        \n",
    "        return x\n",
    "\n",
    "# Create the model\n",
    "model = HybridCNNTransformer()\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.load_state_dict(torch.load('best_model.pth'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data = TensorDataset(torch.from_numpy(X_test).float(), torch.from_numpy(y_test).long())\n",
    "batch_size = 64\n",
    "test_loader = DataLoader(test_data, shuffle=False, batch_size=batch_size)\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def test(model, criterion, test_loader):\n",
    "    model.eval()  # 将模型设置为评估模式\n",
    "    test_loss = 0.0\n",
    "    correct = 0\n",
    "    total = 0\n",
    "\n",
    "    with torch.no_grad():  # 关闭梯度计算\n",
    "        for inputs, labels in test_loader:\n",
    "            outputs = model(inputs)\n",
    "            loss = criterion(outputs, labels)\n",
    "            test_loss += loss.item()\n",
    "            \n",
    "            # 获取每个样本的预测结果（最大概率的类别）\n",
    "            _, predicted = torch.max(outputs.data, 1)\n",
    "            total += labels.size(0)\n",
    "            correct += (predicted == labels).sum().item()\n",
    "\n",
    "    avg_test_loss = test_loss / len(test_loader)\n",
    "    test_accuracy = correct / total\n",
    "    print(f'Test Loss: {avg_test_loss:.4f}, Test Accuracy: {test_accuracy:.4f}')\n",
    "\n",
    "# 加载最佳模型参数\n",
    "model.load_state_dict(torch.load('best_model.pth'))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Loss: 1.0907, Test Accuracy: 0.5718\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# 在测试集上评估模型\n",
    "test(model, criterion, test_loader)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tf2",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
